{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_headers = {\n",
    "        \"method\": \"GET\",\n",
    "        \"http_version\": \"HTTP/2\",\n",
    "        \"Host\": \"xistore.by\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:134.0) Gecko/20100101 Firefox/134.0\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3\",\n",
    "        \"Accept-Encoding\": \"gzip, deflate, br, zstd\",\n",
    "        \"DNT\": \"1\",\n",
    "        \"Sec-GPC\": \"1\",\n",
    "        \"Connection\": \"keep-alive\",\n",
    "        \"Cookie\": \"hg-client-security=2raddTr8odLrsgYb67RiYQe1LA9; PHPSESSID=wJ2S6mmhESmmdK1Z148IspYnFyPx3lD2; VISIT_USER_ID=BA2F506F-4E40-C9BA-82FF-E3A1546CDCA6; BITRIX_SM_5_SALE_UID=123462632; xistore_banner_show=167986; _gcl_au=1.1.628187606.1736801209; _ga_63ZME06VVY=GS1.1.1736801209.1.0.1736801209.60.0.0; _ga=GA1.1.83084367.1736801210\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Sec-Fetch-Dest\": \"document\",\n",
    "        \"Sec-Fetch-Mode\": \"navigate\",\n",
    "        \"Sec-Fetch-Site\": \"cross-site\",\n",
    "        \"Referer\": \"https://xistore.by/catalog/telefony/?PAGEN_1=1\",\n",
    "        \"Priority\": \"u=0, i\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phones_links = []\n",
    "\n",
    "# XI-store parser\n",
    "# Phone catalog pages parser\n",
    "for i in range(1, 6):\n",
    "    url = f\"https://xistore.by/catalog/smart_televizory/?PAGEN_1={i}\"\n",
    "    r = requests.get(url, headers=request_headers)\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    # Find all phone links on the page\n",
    "    for a in soup.find_all('a', class_='search__page_item-name'):\n",
    "        href = a.attrs['href']\n",
    "        absolute_url = 'https://xistore.by' + href\n",
    "        all_phones_links.append(absolute_url)\n",
    "        print(len(all_phones_links))\n",
    "    time.sleep(random.randint(1, 3))\n",
    "\n",
    "# /catalog/apple/smartfon_iphone_14_pro/\n",
    "# https://xistore.by/catalog/apple/smartfon_iphone_14_pro/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phones_links = list(set(all_phones_links))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv(product_data_list, filename='notebooks.csv'):\n",
    "    with open(filename, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['name', 'description', 'reviews', 'shops_availability', 'price', 'full_price', 'brand', 'remind_status', 'url', 'category', 'images', 'characteristics'] \n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for product_data in product_data_list:\n",
    "            # Convert lists and dictionaries to JSON strings for CSV storage\n",
    "            product_data['reviews'] = json.dumps(product_data['reviews'])\n",
    "            product_data['shops_availability'] = json.dumps(product_data['shops_availability'])\n",
    "\n",
    "            product_data['images'] = json.dumps(product_data['images'])\n",
    "            product_data['characteristics'] = json.dumps(product_data['characteristics'])\n",
    "            writer.writerow(product_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product_data = []\n",
    "\n",
    "# Collect detail information\n",
    "for link in tqdm(all_phones_links):\n",
    "    print(link)\n",
    "    try:\n",
    "        response = requests.get(link, headers=request_headers)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        product_data = {}\n",
    "\n",
    "        # Name\n",
    "        product_data['name'] = soup.find('h1').text.strip()\n",
    "\n",
    "        try:\n",
    "            description = soup.find('div', class_='detail-text-description basic--content').text.strip()\n",
    "        except:\n",
    "            meta_description = soup.find('meta', attrs={'itemprop': 'description'})\n",
    "            description = meta_description['content'].strip() if meta_description else \"\"\n",
    "            \n",
    "        product_data['description'] = description\n",
    "\n",
    "        # Reviews (currently placeholder, needs more complex logic to scrape reviews)\n",
    "        product_data['reviews'] = [] # Placeholder for now,  \n",
    "\n",
    "        # Shops availability (requires more sophisticated logic if data isn't simply embedded)\n",
    "        availability_scripts = soup.find_all('div', class_=lambda text: text and 'wrapped-city city-wrap' in text)\n",
    "        shops_list = []\n",
    "        if availability_scripts:\n",
    "            for script in availability_scripts:\n",
    "                shop_data = {}\n",
    "                try: \n",
    "                    shop_data['city'] = script.find('div', class_='pa-heading').text.strip()\n",
    "                    for shop_block in script.find_all('div', class_='pa-result_item'):\n",
    "                        shop_data['name'] = shop_block.find('div', class_='pa-result_title').text.strip()\n",
    "                        shop_availability = shop_block.find('div', class_=lambda x: x and x.startswith('count-code'))\n",
    "                        if shop_availability.attrs['class'][0].endswith('available-res'):\n",
    "                            shop_data['availability'] = False\n",
    "                        else:\n",
    "                            shop_data['availability'] = True\n",
    "                        shop_data['worktime'] = shop_block.find('div', class_='pa-result_time').find('p', class_='pa-result_info-data').text.strip()\n",
    "                        shop_data['adress'] = shop_block.find('div', class_='pa-result_adress').find('p', class_='pa-result_info-data').text.strip()\n",
    "                        # print(shop_data)\n",
    "                        shops_list.append(shop_data.copy())\n",
    "                except (IndexError, json.JSONDecodeError):\n",
    "                    product_data['shops_availability'] = {} # Handle errors gracefully\n",
    "                    print(f\"Error parsing availability data for {url}\")\n",
    "                \n",
    "        product_data['shops_availability'] = shops_list\n",
    "\n",
    "        # Price (needs better error handling)\n",
    "        price_element = soup.find('span', class_='count price-color')\n",
    "        if price_element:\n",
    "            price_str = price_element.text.replace(' ', '').replace('<sup>', '.').replace('</sup>', '').strip()\n",
    "            product_data['price'] = float(price_str) if price_str else None\n",
    "        \n",
    "        # Discount\n",
    "        old_price_element = soup.find('span', class_='old-price')\n",
    "        if old_price_element and price_element:\n",
    "            old_price_str = old_price_element.text.replace(' ', '').replace('<sup>', '.').replace('</sup>', '').strip()\n",
    "            old_price = float(old_price_str) if old_price_str else 0.0\n",
    "            product_data['full_price'] = old_price\n",
    "        else:\n",
    "            product_data['full_price'] = 0.0\n",
    "\n",
    "        # Brand (meta tag)\n",
    "        product_data['brand'] = soup.find('meta', attrs={'itemprop': 'name'})['content']\n",
    "\n",
    "        # Remind status (placeholder -  logic depends on how it's indicated on the page)\n",
    "        product_data['remind_status'] = any([shop['availability'] for shop in product_data['shops_availability']])\n",
    "\n",
    "        # URL\n",
    "        product_data['url'] = url\n",
    "        \n",
    "        # Category\n",
    "        category_element = soup.find('a', class_='current') # Assuming category in breadcrumb\n",
    "        product_data['category'] = category_element.text.strip() if category_element else \"Unknown\"\n",
    "\n",
    "\n",
    "        # Images\n",
    "        product_data['images'] = [img['src'] for img in soup.find_all('img', itemprop='image')]\n",
    "\n",
    "\n",
    "        # Characteristics \n",
    "        product_data['characteristics'] = []\n",
    "        characteristics_containers = soup.select('.characteristic--list')  # Select all characteristic lists\n",
    "        for container in characteristics_containers:\n",
    "            for item in container.select('.characteristic--item'):  # Iterate through characteristics within each list\n",
    "                name = item.select_one('.name').text.strip()\n",
    "                value = item.select_one('.characteristic').text.strip()\n",
    "                product_data['characteristics'].append({'name': name, 'value': value})\n",
    "                \n",
    "        print(product_data)\n",
    "        time.sleep(random.randint(1, 3))\n",
    "        all_product_data.append(product_data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching URL {link}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv(all_product_data, filename='televizory.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data['category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script.find_all('div', class_='pa-result_item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.html', 'w') as file:\n",
    "    file.write(soup.prettify())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
